{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "####*IMPORANT*: Have to do this line *before* importing tensorflow\n",
    "os.environ['PYTHONHASHSEED']=str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import imgaug as ia\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from numpy import asarray\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from skimage.io import imread\n",
    "from skimage import exposure, color\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../../sensix_daninhas/dataset/train'\n",
    "test_data_path  = '../../sensix_daninhas/dataset/validation'\n",
    "\n",
    "img_rows = 100\n",
    "img_cols = 100\n",
    "epochs = 200\n",
    "batch_size = 20\n",
    "n_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images :  2470\n",
      "Test Images  :  707\n"
     ]
    }
   ],
   "source": [
    "num_of_train_samples = len(glob.glob(train_data_path + \"/**/*\" + \".jpg\" , recursive=True))\n",
    "num_of_test_samples  = len(glob.glob(test_data_path + \"/**/*\" + \".jpg\"  , recursive=True))\n",
    "print(\"Train Images : \", num_of_train_samples)\n",
    "print(\"Test Images  : \", num_of_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_func_1(img):\n",
    "    '''\n",
    "    img: array que representa a imagem que será modificada:\n",
    "    \n",
    "    description: Representa efeitos relacionados a coloração da imagem. Nenhuma\n",
    "    rotação ou aproximação (zoom) é dado. Apenas possui filtros que alteram as \n",
    "    caracteristicas gerais das imagens\n",
    "    \n",
    "    return: array\n",
    "    O array retornado representa a imagem modificada\n",
    "    '''\n",
    "    img = img.astype('uint8')\n",
    "    if random_func(percentage = 10):\n",
    "        seq = iaa.Sequential([\n",
    "            #iaa.Affine(rotate=(0, 90)),\n",
    "            #iaa.Crop(percent=(0.1, 0.2)),\n",
    "            iaa.LinearContrast((1.0, 1.9)),\n",
    "            iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "            iaa.AdditiveGaussianNoise(scale=(10, 20)),\n",
    "            #iaa.Crop(percent=(0, 0.2)),\n",
    "            iaa.AddToBrightness((-30, 30)),\n",
    "            iaa.AddToHue((-50, 50)),\n",
    "            #iaa.flip.Fliplr(0.5)\n",
    "            #iaa.AllChannelsHistogramEqualization()\n",
    "        ],\n",
    "        random_order=True)\n",
    "        images_aug = seq(image=img)\n",
    "    else:\n",
    "        images_aug = img\n",
    "    \n",
    "    images_aug = np.expand_dims(images_aug, axis=0)\n",
    "    images_aug = images_aug.astype('float32')\n",
    "    return (images_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED']=str(1)\n",
    "    tf.random.set_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2925 images belonging to 2 classes.\n",
      "Found 820 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   #preprocessing_function=prepare_dataset_func_1,\n",
    "                                   #fill_mode='constant',\n",
    "                                   )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                  )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_path,\n",
    "                                                    target_size=(img_rows, img_cols),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary',\n",
    "                                                    )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(test_data_path,\n",
    "                                                        target_size=(img_rows, img_cols),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='binary',\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 98, 98, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 49, 49, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 47, 47, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                204864    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 210,961\n",
      "Trainable params: 210,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reset_random_seeds()\n",
    "\n",
    "visible = tf.keras.layers.Input(shape=(img_rows, img_cols, n_channels))\n",
    "conv1 = tf.keras.layers.Conv2D(8, (3,3), activation='relu')(visible)\n",
    "pooling1 = tf.keras.layers.MaxPooling2D(2, 2)(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(16, (3,3), activation='relu')(pooling1)\n",
    "pooling2 = tf.keras.layers.MaxPooling2D(2,2)(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(pooling2)\n",
    "pooling3 = tf.keras.layers.MaxPooling2D(2,2)(conv3)\n",
    "flat = tf.keras.layers.Flatten()(pooling3)\n",
    "hidden1 = tf.keras.layers.Dense(64, activation='relu')(flat)\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid')(hidden1)\n",
    "\n",
    "model = tf.keras.Model(inputs=visible, outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "123/123 [==============================] - 9s 70ms/step - loss: 0.3130 - accuracy: 0.8764 - val_loss: 0.2320 - val_accuracy: 0.8529\n",
      "Epoch 2/2\n",
      "123/123 [==============================] - 8s 69ms/step - loss: 0.1076 - accuracy: 0.9550 - val_loss: 0.2399 - val_accuracy: 0.8543\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#callbacks = CallbackStop()\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch= num_of_train_samples // batch_size,\n",
    "                    epochs=2,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=num_of_test_samples // batch_size,\n",
    "                    #callbacks=[callbacks]\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
